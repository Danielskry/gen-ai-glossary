{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Generative AI glossary","text":"<p>A shared glossary to keep generative AI terminology clear, consistent, and discoverable \ud83e\udd16 </p> <p>Live docs: https://danielskry.github.io/gen-ai-glossary/</p> <p>This repository is a living glossary for concepts in generative AI, agentic AI, orchestration, retrieval, and context engineering. The field shifts quickly, so terminology and aliases change often. This project tracks established meanings, alternate names, and sources in one place. </p> <p>This glossary is community maintained. Terms update as research and usage evolve.</p>"},{"location":"#explore-the-glossary","title":"Explore the glossary","text":"<ul> <li>Agent concepts</li> <li>Context engineering</li> <li>Memory systems</li> <li>Orchestration &amp; tool use</li> <li>Retrieval &amp; RAG patterns</li> </ul>"},{"location":"#why-this-project-matters","title":"Why this project matters","text":"<ul> <li>Clear definitions. Concepts evolve fast and communities often use multiple names. This glossary helps keep meaning stable and discoverable.</li> <li>Good sources only. Every entry references documentation or research that can be traced and verified.</li> <li>Single data source. <code>data/terms.json</code> drives everything: definitions, aliases, categories, Markdown, navigation, and the docs site.</li> <li>Built for contributors. Validation and CI ensure that edits stay consistent and up to date as the glossary grows.</li> </ul>"},{"location":"#structure-of-the-repository","title":"Structure of the repository","text":"Path Description <code>data/terms.json</code> The authoritative list of terms, aliases, categories, and sources. <code>data/terms.schema.json</code> JSON schema that enforces formatting and field rules. <code>scripts/glossary.py</code> Utility script for validation and automatic docs generation. <code>scripts/publish_docs.py</code> Builds the MkDocs site into <code>docs/</code> (plus <code>.nojekyll</code>) for GitHub Pages. <code>docs_src/glossary/</code> Generated term cards for the documentation site. Do not edit manually. <code>mkdocs.yml</code> MkDocs Material configuration, including navigation and styling. <code>.github/workflows/*.yml</code> CI pipelines for validation and automated GitHub Pages deployment."},{"location":"#quick-start","title":"Quick start","text":"<ol> <li><code>pip install -r requirements.txt</code></li> <li>Make your edits in <code>data/terms.json</code> (add terms, aliases, or better sources).</li> <li><code>python scripts/glossary.py validate</code> \u2013 schema, duplicates, and generated headings.</li> <li><code>python scripts/glossary.py generate</code> \u2013 refresh Markdown + nav.</li> <li><code>mkdocs serve</code> \u2013 preview at http://127.0.0.1:8000/</li> <li><code>python scripts/publish_docs.py</code> \u2013 rebuilds the MkDocs site into <code>docs/</code> for GitHub Pages.</li> </ol> <p>Prefer a dry run first? <code>python scripts/glossary.py generate --dry-run</code></p>"},{"location":"#how-to-help-improve-the-glossary","title":"How to help improve the glossary","text":"<ol> <li>Add or modify entries in <code>data/terms.json</code>, including aliases and reliable references.</li> <li>Re-run the Quick start commands (<code>python scripts/glossary.py validate</code>, <code>python scripts/glossary.py generate</code>, and <code>python scripts/publish_docs.py</code>) so Markdown and <code>docs/</code> reflect your edits.</li> <li>Review the Git diff and commit the JSON, generated Markdown, and refreshed <code>docs/</code> site.</li> <li>Open a pull request with a brief note on the motivation or source quality.</li> </ol> <p>The CI checks ensure that generated files match the source of truth, so builds stay consistent.</p> <p>Example term entry:</p> <pre><code>{\n    \"term\": \"Agent\",\n    \"definition\": \"AI agents are autonomous software systems that use artificial intelligence to perform tasks, make decisions, and interact with their environment on behalf of a user or another system. They apply reasoning, planning, and memory, and can adapt over time to pursue goals more effectively.\",\n    \"category\": \"agents\",\n    \"aliases\": [\"AI agent\", \"autonomous agent\", \"agentic AI\", \"intelligent agent\"],\n    \"sources\": [\n      \"https://cloud.google.com/discover/what-are-ai-agents\",\n      \"https://www.ibm.com/think/topics/ai-agents\",\n      \"https://github.com/resources/articles/what-are-ai-agents\"\n    ]\n  },\n</code></pre>"},{"location":"#contribute","title":"Contribute","text":"<p>Contributions are welcome. If you notice a term that is missing, unclear, or evolving in the field, feel free to propose updates. Discussion first is encouraged, but not required. Please see <code>CONTRUBTIONS.md</code> for more.</p>"},{"location":"glossary/GLOSSARY_AGENTS/","title":"Agent Concepts","text":"<p>Auto-generated from <code>data/terms.json</code>. Do not edit this file manually.</p>"},{"location":"glossary/GLOSSARY_AGENTS/#agent","title":"Agent","text":"<p>AI agents are autonomous software systems that use artificial intelligence to perform tasks, make decisions, and interact with their environment on behalf of a user or another system. They apply reasoning, planning, and memory, and can adapt over time to pursue goals more effectively.</p> <p>Also known as: AI agent, autonomous agent, agentic AI, intelligent agent</p> <p>Sources:</p> <ul> <li>https://cloud.google.com/discover/what-are-ai-agents</li> <li>https://www.ibm.com/think/topics/ai-agents</li> <li>https://github.com/resources/articles/what-are-ai-agents</li> </ul>"},{"location":"glossary/GLOSSARY_CONTEXT_ENGINEERING/","title":"Context Engineering","text":"<p>Auto-generated from <code>data/terms.json</code>. Do not edit this file manually.</p>"},{"location":"glossary/GLOSSARY_CONTEXT_ENGINEERING/#context-window","title":"Context Window","text":"<p>The context window is the amount of information a language model can consider at once when generating a response. It acts as the model's working memory, including both the input provided and the output it has generated so far. A larger context window allows the model to handle longer prompts, maintain coherence over extended interactions, and work with more complex information, while a smaller context window limits how much the model can reference at one time.</p> <p>Also known as: token window</p> <p>Sources:</p> <ul> <li>https://www.coursera.org/articles/context-window</li> <li>https://docs.claude.com/en/docs/build-with-claude/context-windows/</li> </ul>"},{"location":"glossary/GLOSSARY_CONTEXT_ENGINEERING/#prompt","title":"Prompt","text":"<p>A prompt is the input or instruction given to an AI system to guide its output. It provides context, goals, constraints or examples that influence how the model responds. Prompts are written in natural language (and sometimes combined with structured elements), and the clarity and structure of the prompt directly affect the quality of the AI's response.</p> <p>Also known as: prompting, prompt engineering, prompting techniques</p> <p>Sources:</p> <ul> <li>https://dictionary.cambridge.org/dictionary/english/prompt</li> <li>https://www.ulethbridge.ca/teachingcentre/what-are-prompts</li> </ul>"},{"location":"glossary/GLOSSARY_GUARDRAILS/","title":"Guardrails","text":"<p>Auto-generated from <code>data/terms.json</code>. Do not edit this file manually.</p>"},{"location":"glossary/GLOSSARY_GUARDRAILS/#hallucination","title":"Hallucination","text":"<p>AI hallucinations occur when a model generates content that is factually incorrect, logically flawed, or entirely fabricated while presenting it as confident and accurate. These errors stem from limitations in training data, model architecture, bias, faulty grounding, or the probabilistic way large language models generate outputs. Hallucinations can appear as wrong facts, flawed reasoning, or invented details such as nonexistent studies, citations, or events. They influence everything from chat interactions to computer vision systems, and they can undermine trust, harm decision making, and introduce quality and safety risks in fields like healthcare, law, finance, and software development. Reducing hallucinations requires improved data quality, clear model constraints, retrieval augmented grounding, rigorous testing such as red teaming and adversarial evaluation, and ongoing human oversight.</p> <p>Also known as: AI hallucination, model hallucination, LLM hallucination, generative AI hallucination</p> <p>Sources:</p> <ul> <li>https://www.ibm.com/think/topics/ai-hallucinations</li> <li>https://cloud.google.com/discover/what-are-ai-hallucinations</li> <li>https://www.computer.org/publications/tech-news/trends/hallucinations-in-ai-models</li> </ul>"},{"location":"glossary/GLOSSARY_MEMORY/","title":"Memory","text":"<p>Auto-generated from <code>data/terms.json</code>. Do not edit this file manually.</p>"},{"location":"glossary/GLOSSARY_MEMORY/#memory","title":"Memory","text":"<p>Agent memory refers to an AI agent's ability to store and recall information from previous interactions to guide future decisions and improve performance. Memory allows an agent to maintain context, recognize patterns over time, learn from feedback, and adapt to user preferences. In practice, memory often includes short-term memory that tracks the state of an ongoing conversation or task, and long-term memory that stores information across sessions for more persistent personalization and reasoning. While not all agents require memory, it becomes essential for agents that handle multi-step reasoning, goal-oriented tasks, or sustained user interaction.</p> <p>Also known as: agent memory, chat memory, session memory</p> <p>Sources:</p> <ul> <li>https://www.ibm.com/think/topics/ai-agent-memory</li> <li>https://docs.langchain.com/oss/python/langgraph/memory</li> </ul>"},{"location":"glossary/GLOSSARY_ORCHESTRATION/","title":"Orchestration and Tool Use","text":"<p>Auto-generated from <code>data/terms.json</code>. Do not edit this file manually.</p>"},{"location":"glossary/GLOSSARY_ORCHESTRATION/#orchestration","title":"Orchestration","text":"<p>Orchestration is the coordination and management of multiple systems, models, tools, and services to carry out tasks in a structured and reliable way. In the context of AI, orchestration ensures that prompts, workflows, external tools, memory, and control flow work together so the overall system behaves predictably and achieves its intended goals.</p> <p>Also known as: LLM orchestration</p> <p>Sources:</p> <ul> <li>https://www.ibm.com/think/topics/ai-orchestration</li> <li>https://www.databricks.com/glossary/orchestration</li> </ul>"},{"location":"glossary/GLOSSARY_ORCHESTRATION/#tool-calling","title":"Tool Calling","text":"<p>Tool calling (also known as function calling) is the capability for an AI model to invoke external tools, APIs, or systems in order to extend what it can do. It allows the model to access, retrieve, and manipulate data or perform actions outside its training data by passing structured arguments to defined functions or custom tools. This makes it possible to build applications where the model not only reasons and generates language, but also interacts with databases, services, and other software components provided by your application.</p> <p>Also known as: function calling, open functions, actions</p> <p>Sources:</p> <ul> <li>https://www.ibm.com/think/topics/tool-calling</li> <li>https://blog.langchain.com/tool-calling-with-langchain/</li> <li>https://platform.openai.com/docs/guides/function-calling</li> </ul>"},{"location":"glossary/GLOSSARY_RETRIEVAL/","title":"Retrieval and RAG Patterns","text":"<p>Auto-generated from <code>data/terms.json</code>. Do not edit this file manually.</p>"},{"location":"glossary/GLOSSARY_RETRIEVAL/#embedding","title":"Embedding","text":"<p>Embeddings are vector representations of data such as text, images or audio, where each item is mapped to a point in a continuous numerical space. The distance between points reflects semantic similarity, allowing machine learning systems to search, compare, cluster and classify information based on meaning. Embeddings are fundamental for tasks like semantic search, recommendations, anomaly detection and grouping related content.</p> <p>Also known as: vector embedding, embeddings</p> <p>Sources:</p> <ul> <li>https://www.cloudflare.com/learning/ai/what-are-embeddings/</li> <li>https://www.ibm.com/think/topics/embedding</li> <li>https://platform.openai.com/docs/guides/embeddings</li> </ul>"},{"location":"glossary/GLOSSARY_RETRIEVAL/#retrieval-augmented-generation","title":"Retrieval-Augmented Generation","text":"<p>Retrieval-Augmented Generation (RAG) is a technique where a model retrieves relevant information from an external knowledge source and uses it as context before generating a response. This improves the accuracy, grounding and reliability of the model by ensuring that answers are informed by up-to-date and authoritative data beyond the model's original training corpus.</p> <p>Also known as: RAG</p> <p>Sources:</p> <ul> <li>https://aws.amazon.com/what-is/retrieval-augmented-generation/</li> <li>https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/</li> </ul>"},{"location":"glossary/GLOSSARY_RETRIEVAL/#vector-database","title":"Vector Database","text":"<p>A vector database is a database designed to store, manage, and index high-dimensional vector embeddings for efficient similarity search. It represents data as numerical vectors, clusters them based on semantic relatedness, and enables fast retrieval through specialized indexes. Vector databases often support metadata filtering, CRUD operations, and horizontal scaling, making them well suited for AI applications that require low-latency search across large datasets.</p> <p>Also known as: vector store</p> <p>Sources:</p> <ul> <li>https://www.ibm.com/think/topics/vector-database</li> <li>https://www.pinecone.io/learn/vector-database/</li> <li>https://learn.microsoft.com/en-us/data-engineering/playbook/solutions/vector-database/</li> </ul>"}]}